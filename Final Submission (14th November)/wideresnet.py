# -*- coding: utf-8 -*-
"""WideResNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v75Zs90TzQuZDO7se2Kk3PUJm7l1m1cD
"""

# Commented out IPython magic to ensure Python compatibility.
# %config IPCompleter.greedy=True
# from google.colab import drive
# drive.mount('/content/drive')

from __future__ import absolute_import, division, print_function, unicode_literals
import numpy as np
from keras import backend as K
from keras.regularizers import l2
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Convolution2D, MaxPooling2D, AveragePooling2D
from keras.layers import Input, Add, Activation, Dropout, Flatten, Dense
from keras.models import Model
import keras
import tensorflow.compat.v1 as tf
import sys

train_data = np.loadtxt(sys.argv[1])

test_data = np.loadtxt(sys.argv[2])


train_data_x = np.reshape(train_data[:, :-2], (train_data.shape[0], 3, 32, 32))
train_data_x = np.swapaxes(train_data_x, 1, 2)
train_data_x = np.swapaxes(train_data_x, 2, 3)
train_data_y = keras.utils.to_categorical(train_data[:, -1:], 100)


def initial(inp):
    x = Convolution2D(16, (3, 3), padding='same', kernel_initializer='he_normal',
                      use_bias=False)(inp)

    x = BatchNormalization(axis=-1, momentum=0.1,
                           epsilon=1e-5, gamma_initializer='uniform')(x)
    x = Activation('relu')(x)
    return x


def expand(inp, base, k, strides=(1, 1)):
    x = Convolution2D(base * k, (3, 3), padding='same', strides=strides, kernel_initializer='he_normal',
                      use_bias=False)(inp)

    x = BatchNormalization(axis=-1, momentum=0.1,
                           epsilon=1e-5, gamma_initializer='uniform')(x)
    x = Activation('relu')(x)

    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',
                      use_bias=False)(x)

    skip = Convolution2D(base * k, (1, 1), padding='same', strides=strides, kernel_initializer='he_normal',
                         use_bias=False)(inp)

    m = Add()([x, skip])

    return m


def conv_block(inp, base, k=1, dropout=0.0):
    x = BatchNormalization(axis=-1, momentum=0.1,
                           epsilon=1e-5, gamma_initializer='uniform')(inp)
    x = Activation('relu')(x)
    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',
                      use_bias=False)(x)

    if dropout > 0.0:
        x = Dropout(dropout)(x)

    x = BatchNormalization(axis=-1, momentum=0.1,
                           epsilon=1e-5, gamma_initializer='uniform')(x)
    x = Activation('relu')(x)
    x = Convolution2D(base * k, (3, 3), padding='same', kernel_initializer='he_normal',
                      use_bias=False)(x)

    m = Add()([inp, x])
    return m


def WideResNet(input_dim, nb_classes=100, N=2, k=1, dropout=0.0):
    inp = Input(shape=input_dim)

    x = initial(inp)

    x = expand(x, 16, k)

    for i in range(N - 1):
        x = conv_block(x, 16, k, dropout)

    x = BatchNormalization(axis=-1, momentum=0.1,
                           epsilon=1e-5, gamma_initializer='uniform')(x)
    x = Activation('relu')(x)

    x = expand(x, 32, k, strides=(2, 2))

    for i in range(N - 1):
        x = conv_block(x, 32, k, dropout)

    x = BatchNormalization(axis=-1, momentum=0.1,
                           epsilon=1e-5, gamma_initializer='uniform')(x)
    x = Activation('relu')(x)

    x = expand(x, 64, k, strides=(2, 2))

    for i in range(N - 1):
        x = conv_block(x, 64, k, dropout)

    x = BatchNormalization(axis=-1, momentum=0.1,
                           epsilon=1e-5, gamma_initializer='uniform')(x)
    x = Activation('relu')(x)

    x = AveragePooling2D((8, 8))(x)
    x = Flatten()(x)

    x = Dense(nb_classes, activation='softmax')(x)

    model = Model(inp, x)
    return model


model = WideResNet((32, 32, 3), nb_classes=100, N=4, k=4, dropout=0.1)
model.compile(optimizer='adam', loss='categorical_crossentropy',
              metrics=['accuracy'])
# checkpointer = keras.callbacks.ModelCheckpoint(filepath='/content/drive/My Drive/A3ML_data/bestweights_resnext.hdf5',
#                                monitor='val_acc', verbose=1, save_best_only=True,
#                                save_weights_only=True)
earlystopper = keras.callbacks.EarlyStopping(
    monitor='val_loss', patience=3, verbose=1)
# callbacks = [checkpointer, earlystopper]
callbacks = [earlystopper]
model.summary()

model.fit(train_data_x, train_data_y, epochs=50,
          validation_split=0.2, shuffle=True, callbacks=callbacks)

test_data_x = np.reshape(test_data[:, :-2], (test_data.shape[0], 3, 32, 32))
test_data_x = np.swapaxes(test_data_x, 1, 2)
test_data_x = np.swapaxes(test_data_x, 2, 3)

# model.load_weights('/content/drive/My Drive/A3ML_data/bestweights_resnext.hdf5')
test_data_y = np.argmax(model.predict(test_data_x), axis=1)
np.savetxt(sys.argv[3], test_data_y, fmt='%i')
