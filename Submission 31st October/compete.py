# -*- coding: utf-8 -*-
"""ResNeXt.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jpj8zGidmGNmfBSHAGuU4eOlmAXkWCv4
"""

# Commented out IPython magic to ensure Python compatibility.
# %config IPCompleter.greedy=True

import sys
import numpy as np

train_data = np.loadtxt(sys.argv[1])
test_data = np.loadtxt(sys.argv[2])

from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import tensorflow.keras as keras

train_data_x = np.reshape(train_data[:, :-2], (train_data.shape[0], 3, 32, 32))
train_data_x = np.swapaxes(train_data_x, 1 ,2)
train_data_x = np.swapaxes(train_data_x, 2, 3)
train_data_y = keras.utils.to_categorical(train_data[:, -1:], 100)

# ResNeXt Layer
class ResidualLayer(keras.layers.Layer):
    def __init__(self, cardinality, out_dim, inner_dim):
        super(ResidualLayer, self).__init__()
        self.cardinality = cardinality
        self.out_dim = out_dim
        self.inner_dim = inner_dim

        self.transform1 = list()
        self.transform2 = list()
        for i in range(self.cardinality):
            self.transform1.append((keras.layers.Conv2D(self.inner_dim, [1, 1], padding='SAME', kernel_initializer='he_normal', bias_initializer='he_normal'), keras.layers.ReLU()))
            self.transform2.append((keras.layers.Conv2D(self.inner_dim, [3, 3], padding='SAME', kernel_initializer='he_normal', bias_initializer='he_normal'), keras.layers.ReLU()))

        self.concat = keras.layers.Concatenate()

    def build(self, input_shape):
        self.in_dim = int(input_shape[-1])
        self.transition = keras.layers.Conv2D(self.in_dim, [3, 3], padding='SAME', kernel_initializer='he_normal', bias_initializer='he_normal')
        self.transition_relu = keras.layers.ReLU()

    def call(self, input_x):
        # split + transform(bottleneck) + transition + merge
        splits = list()
        for i in range(self.cardinality):
            split = self.transform1[i][0](input_x)
            split = self.transform1[i][1](split)
            split = self.transform2[i][0](split)
            split = self.transform2[i][1](split)
            splits.append(split)
        x = self.concat(splits)
        x = self.transition(x)
        x = self.transition_relu(x+input_x)

        return x

# bottle neck module ResNeXt Model Class
class ResNeXt(keras.Model):
    def __init__(self):
        super(ResNeXt, self).__init__(name='')

        # first layer
        self.first_layer_conv = keras.layers.Conv2D(64, [3, 3], padding='VALID', kernel_initializer='he_normal', bias_initializer='he_normal')
        # maybe set non-default params
        self.first_layer_bn = keras.layers.BatchNormalization()
        self.first_layer_relu = keras.layers.ReLU()

        # residual layers
        self.res_stage1 = list()
        for i in range(3):
            self.res_stage1.append(ResidualLayer(32, 64, 4))
        self.down_sample1 = keras.layers.Conv2D(32, [3, 3], padding='VALID', kernel_initializer='he_normal', bias_initializer='he_normal')
        self.down_sample1_relu = keras.layers.ReLU()

        self.res_stage2 = list()

        for i in range(3):
            self.res_stage2.append(ResidualLayer(32, 64, 4))
        self.down_sample2 = keras.layers.Conv2D(16, [3, 3], padding='VALID', kernel_initializer='he_normal', bias_initializer='he_normal')
        self.down_sample2_relu = keras.layers.ReLU()

        self.res_stage3 = list()
        for i in range(3):
            self.res_stage3.append(ResidualLayer(32, 64, 4))
        self.down_sample3 = keras.layers.Conv2D(8, [3, 3], padding='VALID', kernel_initializer='he_normal', bias_initializer='he_normal')
        self.down_sample3_relu = keras.layers.ReLU()
        
        # final layers
        # data_format: A string, one of channels_last (default) or channels_first
        self.final_ga = keras.layers.GlobalMaxPooling2D()
        self.final_flatten = keras.layers.Flatten()
        self.final_linear = keras.layers.Dense(100, kernel_initializer='he_normal', bias_initializer='he_normal')

    def call(self, x):
        # first layer
        x = self.first_layer_conv(x)
        x = self.first_layer_bn(x)
        x = self.first_layer_relu(x)

        # residual layer
        for i in range(3):
            x = self.res_stage1[i](x)
        x = self.down_sample1(x)
        x = self.down_sample1_relu(x)

        for i in range(3):
            x = self.res_stage2[i](x)
        x = self.down_sample2(x)
        self.down_sample2_relu = keras.layers.ReLU()

        for i in range(3):
            x = self.res_stage3[i](x)
        x = self.down_sample3(x)
        self.down_sample3_relu = keras.layers.ReLU()

        x = self.final_ga(x)
        x = self.final_flatten(x)
        x = self.final_linear(x)

        return x

model = ResNeXt()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
checkpointer = keras.callbacks.ModelCheckpoint(filepath='bestweights_resnext.hdf5',
                               monitor='val_acc', verbose=1, save_best_only=True,
                               save_weights_only=True)
earlystopper = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5, verbose=1)
callbacks = [checkpointer, earlystopper]

model.fit(train_data_x, train_data_y, epochs=10, validation_split=0.1, shuffle=True, callbacks=callbacks)

test_data_x = np.reshape(test_data[:, :-2], (test_data.shape[0], 3, 32, 32))
test_data_x = np.swapaxes(test_data_x, 1 ,2)
test_data_x = np.swapaxes(test_data_x, 2, 3)

model.load_weights('bestweights_resnext.hdf')
test_data_y = np.argmax(model.predict(test_data_x), axis=1)
np.savetxt(sys.argv[3], test_data_y, fmt='%i')